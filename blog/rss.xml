<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>老司机的文档集 Blog</title>
        <link>https://itxx00.github.io/notes/blog</link>
        <description>老司机的文档集 Blog</description>
        <lastBuildDate>Mon, 25 Dec 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-Hans</language>
        <item>
            <title><![CDATA[如何通过loop模拟一个lvm逻辑卷]]></title>
            <link>https://itxx00.github.io/notes/blog/2023/12/25/create-loop-lvm</link>
            <guid>https://itxx00.github.io/notes/blog/2023/12/25/create-loop-lvm</guid>
            <pubDate>Mon, 25 Dec 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[年纪大了记性不好]]></description>
            <content:encoded><![CDATA[<p>某些时候我们需要一个lvm逻辑卷，但是又没有多余的磁盘设备可用，这时可以通过模拟的方式创建一个设备出来，步骤如下：</p>
<pre><code class="language-bash"># 首先创建一个虚拟block文件
dd if=/dev/zero of=pv1 bs=1M count=5000
# 然后通过losetup将其挂载到loop0设备上
sudo losetup /dev/loop0 pv1
# 这时可以对loop0设备进行操作，当做一个block设备使用
sudo pvcreate /dev/loop0
sudo vgcreate vg0 /dev/loop0
sudo lvcreate -n lv0 --size 1G vg0
# 创建好lv之后就可以继续格式化文件系统
sudo mkfs.ext4 /dev/vg0/lv0
sudo mkdir /data01
sudo mount /dev/vg0/lv0 /data01
</code></pre>
<p>这样我们就完成了通过dd出一个空文件，然后通过loop设备模拟了一个lvm逻辑卷出来。</p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[普通用户执行systemctl启停服务禁用密码认证]]></title>
            <link>https://itxx00.github.io/notes/blog/2023/02/02/non-root-systemd</link>
            <guid>https://itxx00.github.io/notes/blog/2023/02/02/non-root-systemd</guid>
            <pubDate>Thu, 02 Feb 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[年纪大了记性不好]]></description>
            <content:encoded><![CDATA[<p>在CentOS系统中默认情况下，使用普通用户管理系统服务启停会要求认证，输出类似如下：</p>
<pre><code class="language-bash">systemctl restart xxx
==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===
Authentication is required to manage system services or units.
Authenticating as: root
Password:


</code></pre>
<p>这里的认证是systemd引入polkit认证，可以通过polkit配置文件来改变默认行为，例如和配置某个普通用户免密执行sudo一样，这里也可以配置polkit认证免密：</p>
<p>配置文件路径:/etc/polkit-1/localauthority/50-local.d/xxx.pkla</p>
<p>例如 vi /etc/polkit-1/localauthority/50-local.d/xxx.pkla</p>
<pre><code class="language-bash">
[disable auth for admin]
Identity=unix-user:yourusername
Action=*
ResultActive=yes
ResultAny=yes
ResultInactive=yes
</code></pre>
<p>保存配置立即生效，再执行systemctl restart就不会提示认证了。</p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[influxQL常用语句整理]]></title>
            <link>https://itxx00.github.io/notes/blog/2022/12/28/influxdb-ql-use-case</link>
            <guid>https://itxx00.github.io/notes/blog/2022/12/28/influxdb-ql-use-case</guid>
            <pubDate>Wed, 28 Dec 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[年纪大了记性不好]]></description>
            <content:encoded><![CDATA[<h2 id="db">db</h2>
<pre><code>show databases
use db1
show retention policies
create database db2 with duration 30d replication 2
</code></pre>
<h2 id="measurements">measurements</h2>
<pre><code>use db1
show measurements
show measurements with measurement =~ /cpu/

</code></pre>
<h2 id="tag">tag</h2>
<pre><code>show tag keys from cpu
show tag values from cpu with key=cputype
</code></pre>
<h2 id="field">field</h2>
<pre><code>show field keys from cpu

</code></pre>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[mac上使用docker交叉静态编译jq和fio]]></title>
            <link>https://itxx00.github.io/notes/blog/2022/11/08/static-build-jq-fio</link>
            <guid>https://itxx00.github.io/notes/blog/2022/11/08/static-build-jq-fio</guid>
            <pubDate>Tue, 08 Nov 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[描述]]></description>
            <content:encoded><![CDATA[<h2 id="思路">思路</h2>
<p>为了得到静态编译的jq和fio程序二进制,同时又需要x86_64和aarch64的版本,可以利用docker的buildx实现交叉编译</p>
<h2 id="步骤">步骤</h2>
<p>编译fio</p>
<pre><code class="language-bash">mkdir fio &amp;&amp; cd fio
vi Dockerfile
</code></pre>
<p>Dockerfile 如下</p>
<pre><code>FROM ubuntu as build
WORKDIR /opt
ARG VER=fio-3.33
RUN if [  -e /etc/apt/sources.list ];then sed -ri 's/[a-zA-Z0-9.]+(debian.org|ubuntu.com)/mirrors.volces.com/g' /etc/apt/sources.list; fi &amp;&amp; \
    export DEBIAN_FRONTEND=noninteractive &amp;&amp; \
    apt-get update &amp;&amp; \
    apt-get install -y git gcc make cmake libaio1 libaio-dev zlib1g zlib1g-dev
RUN git clone https://github.com/axboe/fio.git &amp;&amp; \
    cd fio  &amp;&amp; \
    git checkout ${VER}
RUN cd fio  &amp;&amp; \
    ./configure --build-static
RUN cd fio &amp;&amp; make &amp;&amp; make install  &amp;&amp; \
    strip `which fio` &amp;&amp; cp `which fio` /fio-$(dpkg --print-architecture)

FROM scratch AS bin
COPY --from=build /fio-* /
</code></pre>
<p>执行编译</p>
<pre><code class="language-bash">docker buildx build . --platform linux/amd64 --target bin --output .
docker buildx build . --platform linux/arm64 --target bin --output .
</code></pre>
<p>编译成功会在当前目录得到可执行程序fio-amd64和fio-arm64两个文件.</p>
<p>jq编译步骤类似,dockerfile如下:</p>
<pre><code>FROM ubuntu as build
WORKDIR /opt
ARG VER=jq-1.6
RUN if [  -e /etc/apt/sources.list ];then sed -ri 's/[a-zA-Z0-9.]+(debian.org|ubuntu.com)/mirrors.volces.com/g' /etc/apt/sources.list; fi &amp;&amp; \
    export DEBIAN_FRONTEND=noninteractive &amp;&amp; \
    apt-get update &amp;&amp; \
    apt-get install -y build-essential libtool git gcc make cmake autotools-dev autoconf
RUN git clone https://github.com/stedolan/jq.git &amp;&amp; \
    cd jq  &amp;&amp; \
    git checkout ${VER} &amp;&amp; git submodule update --init
RUN cd jq  &amp;&amp; \
    autoreconf -fi &amp;&amp; \
    ./configure --disable-maintainer-mode --disable-valgrind --with-oniguruma=builtin --enable-all-static --prefix=/usr/local
RUN cd jq &amp;&amp; LDFLAGS=-all-static make -j4 &amp;&amp; make install  &amp;&amp; \
    strip /usr/local/bin/jq &amp;&amp; cp /usr/local/bin/jq /jq-$(dpkg --print-architecture)

FROM scratch AS bin
COPY --from=build /jq-* /
</code></pre>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[pre-commit basic usage]]></title>
            <link>https://itxx00.github.io/notes/blog/2022/04/20/pre-commit-basic</link>
            <guid>https://itxx00.github.io/notes/blog/2022/04/20/pre-commit-basic</guid>
            <pubDate>Wed, 20 Apr 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[描述]]></description>
            <content:encoded><![CDATA[<h2 id="install">install</h2>
<pre><code>pip install pre-commit

</code></pre>
<h2 id="init">init</h2>
<pre><code>git clone https://xxx/xxx.git
cd xxx
pre-commit install

pre-commit sample-config &gt;.pre-commit-config.yaml
</code></pre>
<h2 id="test">test</h2>
<pre><code>pre-commit run --all-files
pre-commit run --files xxx.py

</code></pre>
<h2 id="sample-conf">sample conf</h2>
<pre><code>
# See https://pre-commit.com for more information
# See https://pre-commit.com/hooks.html for more hooks
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.1.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files

  - repo: https://github.com/talos-systems/conform
    rev: v0.1.0-alpha.25
    hooks:
      - id: conform
        stages:
          - commit-msg

#  - repo: https://github.com/koalaman/shellcheck-precommit
#    rev: v0.7.2
#    hooks:
#      - id: shellcheck
#        args:
#          - --exclude=SC2009,SC2086

  - repo: https://github.com/5xops/mirrors-shellcheck
    rev: v1.0
    hooks:
      - id: shellcheck


#  - repo: https://github.com/pre-commit/mirrors-mypy
#    rev: v0.770
#    hooks:
#      - id: mypy
#        language: python_venv
#        exclude: ^(docs/|example-plugin/|tests/fixtures)

  - repo: https://gitlab.com/pycqa/flake8.git
    rev: 3.9.2
    hooks:
      - id: flake8
        exclude: $(.tox/|.git/|__pycache__/|build/|dist/|.cache|.eggs/)
        args:
          - --ignore=E501,W503,E722,W605

  - repo: https://github.com/PyCQA/pylint
    rev: v2.12.2
    hooks:
      - id: pylint
        language: python_venv
        args:
          - --disable=C0114,C0115,C0116,C0415,E0401,W1401,R0912,R0914,W0212
          - --max-line-length=120
</code></pre>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[使用cobbler批量安装centos系统]]></title>
            <link>https://itxx00.github.io/notes/blog/2022/04/20/pxe-cobbler-install</link>
            <guid>https://itxx00.github.io/notes/blog/2022/04/20/pxe-cobbler-install</guid>
            <pubDate>Wed, 20 Apr 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[描述]]></description>
            <content:encoded><![CDATA[<h3 id="基本介绍">基本介绍：</h3>
<p>PXE（preboot execute environment）由Intel发明的通过网络快速引导操作系统的技术，其原理是在机器引导时通过server端为网卡DHCP分配IP信息，并通知client端next_server中的tftp地址，client端继续通过tftp下载系统引导镜像，加载并完成启动。这里我们还会用到另外一项技术叫kickstart，由红帽开发，早先用于其系统安装工具中以完成自动化安装，已被众多发行版支持。系统引导时可以通过kickstart配置文件中指定的安装流程自动完成后续步骤，减少人工干预。而通常手工配置dhcp、tftp、kickstart等往往比较繁琐，这里我们会利用红帽开发的另外一款工具cobbler，通过cobbler来完成整个dhcp、tftp、kickstart等组成的server端环境的快速搭建和管理，以此提高效率。</p>
<h3 id="cobbler安装配置">cobbler安装配置：</h3>
<p>我们使用CentOS7作为server端系统，为了节约现场部署时间，我们将提前准备好环境并直接带到现场使用，以下所有操作将在一台ThinkPad上完成。</p>
<p>因私有化环境无需连外网，因此在实际使用时我们为了简化部署流程，可以将selinux和防火墙禁用掉，如需要启用防火墙的话则需要放开http/dhcp/tftp等服务的对应端口：</p>
<pre><code># disable selinux
sed -i 's/^SELINUX=.*$/SELINUX=disabled/' /etc/selinux/config

# disable iptables
systemctl disable firewalld
systemctl stop firewalld

reboot
</code></pre>
<p>&nbsp;安装cobbler及相关的依赖包：cobbler提供了命令行管理工具和一个web管理工具，分别由cobbler和cobbler-web两个包提供</p>
<pre><code>yum install epel-release
yum install cobbler cobbler-web httpd dhcp tftp xinetd rsync bind
</code></pre>
<p>配置cobbler：cobbler配置文件放置在/etc/cobbler目录，在启动之前需要server端IP，dhcp等相关信息，首先修改 /etc/cobbler/settings主配置文件，需要修改的参数有以下：</p>
<pre><code># 通过以下命令生成系统安装后的默认root密码
openssl passwd -1
# 并将生成的密码修改到配置中
default_password_crypted: “$1$RUNYOYnz$QgzdhCD2T7qXWI1IPpAih0”

# server端ip，对外提供dhcp和http服务，必须为一个固定内网ip地址
server: 192.168.1.1

# next_server为tftp服务所在ip，通常是需要和server保持一致
next_server: 192.168.1.1

# 打开cobbler对相关服务的自动管理功能，如配置变更和启停等
manage_dhcp: 1
manage_tftpd：1
</code></pre>
<p>&nbsp;修改依赖组件的配置：</p>
<pre><code>sed -i '/disable/c\\tdisable\t\t\t= no' /etc/xinetd.d/tftp
service xinetd restart
修改dhcp网段：vi /etc/cobbler/dhcp.template
subnet 192.168.1.0 netmask 255.255.255.0 {
     option routers             192.168.1.1;
     option domain-name-servers 192.168.1.1;
&nbsp; &nbsp; &nbsp;range dynamic-bootp &nbsp; &nbsp; &nbsp; &nbsp;192.168.1.100 192.168.1.200;
     option subnet-mask         255.255.255.0;
     filename                   "/pxelinux.0";
     default-lease-time         21600;
     max-lease-time             43200;
     next-server                $next_server;
}
</code></pre>
<p>启动服务：</p>
<pre><code>systemctl start httpd
systemctl start cobblerd

systemctl enable httpd
systemctl enable cobblerd
&nbsp;服务检查：cobbler提供了check命令可用于检查各项配置是否满足需要

cobbler check
# 通常第一次会提示下载loader
cobbler get-loaders
# 如中途修改cobbler配置后需重启cobbler服务
systemctl restart cobblerd
# 如变更了dhcp、tftp等相关信息需重新同步配置
cobbler sync
# 顺便配置好web管理页面的访问密码
htdigest /etc/cobbler/users.digest "Cobbler" cobbler
</code></pre>
<p>&nbsp;可以反复通过check命令来检查环境是否部署OK，并根据实际需求调整各项配置文件，直至check结果复合要求即可。至此cobbler的安装及配置完成。web端工具访问地址：<a href="https://192.168.1.1/cobbler_web">https://192.168.1.1/cobbler_web</a></p>
<h3 id="系统镜像准备">系统镜像准备：</h3>
<p>接下来我们需要将系统镜像导入cobbler中，并自定义安装引导的kickstart配置。我们要部署到节点上的系统是CentOS7。需要注意的是如果需要通过kickstart定制一些基础软件包的安装，那么需要使用软件包更全的DVD iso，因minimal iso中提供的软件包有限。</p>
<pre><code># 将iso挂载到本地目录
mount -o auto CentOS-7-x86_64-DVD-1611.iso /mnt/
# 导入到cobbler中
cobbler import --name=centos7 --arch=x86_64 --path=/mnt
# 查看导入的系统及profile
cobbler distro list
cobbler distro report --name=centos7-x86_64
cobbler profile list
# 卸载iso mount point
umount /mnt/
</code></pre>
<p>&nbsp;可以看到上面的步骤中我们将CentOS7镜像导入到cobbler中，有几个核心概念需要理解：</p>
<p>distro - 及系统发行版本，不同的镜像导入后对应不同的distro，如centos7-x86_64，不同的distro对应不同的引导镜像；</p>
<p>profile - distro的配置文件，一个distro可以有多个profile，默认导入时会自动生成一个profile，不同的profile可以定义不同的kernel选项，使用不同的kickstart配置；</p>
<p>system - 各个机器所使用的profile实例，与机器MAC地址绑定，可以细化到机器级别的自定义安装，如果所有机器安装都是统一的则无需使用system配置。</p>
<p>&nbsp;接下来需要理解的是cobbler中对kickstart文件的管理方式，ks文件是我们需要重点关注的中间产物，决定了系统自动化部署的执行流程和最终效果。ks文件与profile绑定，默认生成的profile会指向一个默认的ks文件，通常我们需要对其进行自定义来满足不同的部署要求。当系统通过PXE引导至profile选择菜单后，一旦选定了需要部署的系统，接下来就会按照该profile所对应的ks文件来执行一系列的安装操作。</p>
<p>在cobbler中ks文件的实例是通过cgi动态生成的，而生成ks实例所依赖的则是ks templates和snippets， cobbler通过template来将ks文件主体流程部分模板化，通过snippets来管理可以在不同ks templates中公用的流程片段。</p>
<p>我们的需求如下：</p>
<p>安装一个精简的CentOS7系统；
同时默认安装一些必要的软件包；
首次安装时只对系统盘进行分区和格式化，其他磁盘不动；
为了便于管理我们将更改网卡名为ethX，且默认禁用IPv6,；
为了方便使用虚拟机测试整个安装流程，需要在磁盘分区时自动适配磁盘名如vda/sda；
安装完成后能对一些基础配置进行初始化。&nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>首先拷贝cobbler默认的template生成一个自定义的ks template，</p>
<pre><code># kickstart template
# (includes %end blocks)
# do not use with earlier distros

#platform=x86, AMD64, or Intel EM64T
# System authorization information
auth --useshadow --enablemd5
# System bootloader configuration
#bootloader --location=mbr
# Partition clearing information
clearpart --all --initlabel
# Use text mode install
text
# Firewall configuration
firewall --disabled
# Run the Setup Agent on first boot
firstboot --disable
# System keyboard
keyboard us
# System language
lang en_US
# Use network installation
url --url=$tree
# If any cobbler repo definitions were referenced in the kickstart profile, include them here.
$yum_repo_stanza
# Network information
$SNIPPET('network_config')
# Reboot after installation
reboot

#Root password
rootpw --iscrypted $default_password_crypted
# SELinux configuration
selinux --disabled
# Do not configure the X Window System
skipx
# System timezone
timezone Asia/Shanghai

# Install OS instead of upgrade
install
# Clear the Master Boot Record
zerombr
# Allow anaconda to partition the system as needed
#autopart
$SNIPPET('main_partition_select')

%pre
$SNIPPET('log_ks_pre')
$SNIPPET('kickstart_start')
$SNIPPET('pre_install_network_config')
$SNIPPET('pre_partition_select_custom')
# Enable installation monitoring
$SNIPPET('pre_anamon')
%end

%packages
@^minimal
@core
chrony
wget
net-tools
python-setuptools
rsync
lrzsz
expect
tcl
ntpdate
-selinux-policy*
-NetworkManager*
-kexec-tools
-snappy
-wpa_supplicant
-ppp
%end

%addon com_redhat_kdump --disable --reserve-mb='auto'

%end

%post --nochroot
$SNIPPET('log_ks_post_nochroot')
%end

%post
$SNIPPET('log_ks_post')
# Start yum configuration
$yum_config_stanza
# End yum configuration
$SNIPPET('post_install_kernel_options')
$SNIPPET('post_install_network_config')
$SNIPPET('download_config_files')
$SNIPPET('cobbler_register')
# Enable post-install boot notification
$SNIPPET('post_anamon')
$SNIPPET('post_install_custom_sys')
# Start final steps
$SNIPPET('kickstart_done')
# End final steps

%end
</code></pre>
<p>&nbsp;注意ks template中的红色部分为我们增加的自定义snippets，第一个pre_partition_select_custom作用是自动根据磁盘类型来生成分区和格式化选项，同时兼容虚拟机和物理机，内容如下：</p>
<pre><code># Determine architecture-specific partitioning needs
if [ -b /dev/vda ]; then
  cat &gt;/tmp/partinfo &lt;&lt; EOF
clearpart --initlabel --all
ignoredisk --only-use=vda
bootloader --location=mbr --boot-drive=vda --driveorder=vda
clearpart --initlabel --drives=vda
part /boot --fstype=ext3 --ondisk=vda --size=500
part / --fstype=xfs --size=1024 --grow --ondisk=vda --asprimary
EOF
elif [ -b /dev/sda ]; then
  cat &gt;/tmp/partinfo &lt;&lt; EOF
clearpart --initlabel --all
ignoredisk --only-use=sda
bootloader --location=mbr --boot-drive=sda --driveorder=sda
part /boot --fstype=ext3 --ondisk=sda --size=500
part / --fstype=xfs --size=100000 --ondisk=sda --asprimary
part /data --fstype=xfs --grow --ondisk=sda
EOF
fi
</code></pre>
<p>&nbsp;第二个post_install_custom_sys作用是在系统安装最后阶段对一些必要的配置进行更改，其中运行的是shell脚本，内容如下：</p>
<pre><code># cat snippets/post_install_custom_sys
if ! grep -q 'custom_sysctl' /etc/sysctl.conf; then
  cat &gt;&gt;/etc/sysctl.conf&lt;&lt;EOF
## custom_sysctl
fs.file-max = 262144
net.core.somaxconn = 10240
vm.swappiness = 0
net.ipv4.ip_local_port_range = 1024 65000
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.core.rmem_default = 1048576
net.core.wmem_default = 524288
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.core.netdev_max_backlog = 2500
net.ipv4.tcp_max_syn_backlog = 40960
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 30
EOF
fi

chmod +x /etc/rc.d/rc.local

if grep -q '^UseDNS' /etc/ssh/sshd_config; then
  sed -i 's/^UseDNS .*/UseDNS no/' /etc/ssh/sshd_config
else
  sed -i 's/^#UseDNS .*/UseDNS no/' /etc/ssh/sshd_config
fi
</code></pre>
<p>接下来还需要修改内核引导参数，完成网卡名字的变更及IPv6禁用：</p>
<pre><code>sed -i -e 's|^GRUB_CMDLINE_LINUX=\"|GRUB_CMDLINE_LINUX=\"net.ifnames=0 biosdevname=0 |g' /etc/default/grub
sed -i -e 's|^GRUB_CMDLINE_LINUX=\"|GRUB_CMDLINE_LINUX=\"ipv6.disable=1 |g' /etc/default/grub
grub2-mkconfig -o /boot/grub2/grub.cfg
</code></pre>
<p>通过这几部分的组合，即可生成一个完整可用的ks文件，下面我将介绍如何通过虚拟机来测试安装。</p>
<h3 id="使用虚拟机测试pxe">使用虚拟机测试PXE</h3>
<p>安装虚拟化相关软件包，使用kvm虚拟机，同时安装图形界面虚拟机管理工具virt-manager方便安装操作。网络选择使用bridge模式,点击新建虚拟机，在安装选项中选择PXE,注意内存设置必须大于1G，否则PXE引导进入系统后很可能报错。</p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[CVM使用ISO镜像安装银河麒麟v10 arm系统]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/12/16/cvm-kylin-v10-iso-install</link>
            <guid>https://itxx00.github.io/notes/blog/2021/12/16/cvm-kylin-v10-iso-install</guid>
            <pubDate>Thu, 16 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[背景：云上没有kylin的arm镜像,需要自己做一个]]></description>
            <content:encoded><![CDATA[<p>背景：云上没有kylin的arm镜像,需要自己做一个</p>
<h2 id="1-准备">1 准备</h2>
<p>iso: Kylin-Server-10-SP2-aarch64-Release-Build09-20210524.iso</p>
<p>一台arm的cvm, 一块数据盘</p>
<p>scp  Kylin-Server-10-SP2-aarch64-Release-Build09-20210524.iso  x.x.x.x:/kylin.iso</p>
<h2 id="2-配置grub">2 配置grub</h2>
<p>修改grub配置增加从iso引导的入口，重启机器时从iso引导进入安装流程</p>
<pre><code>
# cat /etc/grub.d/40_custom
#!/bin/sh
exec tail -n +3 $0
# This file provides an easy way to add custom menu entries.  Simply type the
# menu entries you want to add after this comment.  Be careful not to change
# the 'exec tail' line above.

menuentry 'Install Kylin Linux Advanced Server V10' --class red --class gnu-linux --class gnu --class os {
    set isolabel="Kylin-Server-10"
    set isofile="/kylin.iso"
    insmod iso9660
    loopback loop $isofile
    linux (loop)/images/pxeboot/vmlinuz inst.stage2=hd:LABEL=Kylin-Server-10 ro iso-scan/filename=$isofile console=tty0 video=efifb:off video=VGA-1:640x480-32@60me
    initrd (loop)/images/pxeboot/initrd.img
}

</code></pre>
<p>上面的参数从哪获取来？
1</p>
<pre><code>mount /kylin.iso /mnt
find /mnt -name grub.cfg
</code></pre>
<p>找到的内容作为linux行的参考</p>
<p>2</p>
<pre><code>blkid /kylin.iso
</code></pre>
<p>可以获得isolabel信息</p>
<p>下一步</p>
<pre><code>vi /etc/default/grub
#修改GRUB_TIMEOUT=60 增加timeout方便web vnc登录操作
grub2-mkconfig --ouput=/boot/grub2/grub.cfg
sync
reboot
</code></pre>
<h2 id="3-开始装系统">3 开始装系统</h2>
<p>系统会安装到数据盘，因为系统盘被iso占用，mount状态无法使用，必须有独立的数据盘用来装系统
注意安装cloud-init包。</p>
<h2 id="4-制作云镜像">4 制作云镜像</h2>
<p>重启回到原先的系统</p>
<pre><code>yum -y install qemu-img
qemu-img convert -f raw -O qcow2 /dev/vdb /kylin.qcow2
</code></pre>
<h2 id="5-镜像创建cvm后启动失败问题一例">5 镜像创建CVM后启动失败问题一例</h2>
<h3 id="报错信息如下">报错信息如下：</h3>
<pre><code>/dev/disk/by-uuid/bed44859-b637-4490-b7f9-f62f952f6hfa Warning:does not exist

Generating "/run/initramfs/rdsosreport.txt"

Entering emergency mode. Exit the shell to continue."journalctl" to view system logs.TypeYou might want to save "/run/initramfs/rdsosreport.txt" to a USB stick or /bootaftermounting them and attach it to a bug report.
</code></pre>
<h3 id="原因分析">原因分析：</h3>
<h5 id="1virtio驱动安装的不准确或者异常">1.virtio驱动安装的不准确或者异常</h5>
<h5 id="2内核缺陷本身导致">2.内核缺陷本身导致</h5>
<h3 id="解决方法">解决方法：</h3>
<h5 id="1virtio驱动的修复">1.Virtio驱动的修复</h5>
<pre><code>查询
grep -i virtio /boot/config-$(uname -r)
是否包含在临时文件系统
lsinitrd /boot/initramfs-$(uname -r).img | grep virtio
修复临时文件系统
vim /etc/dracut.conf
add_drivers+="virtio_blk virtio_scsi virtio_net virtio_pci virtio_ring virtio"
dracut -f
</code></pre>
<h5 id="2内核缺陷规避">2.内核缺陷规避</h5>
<pre><code>echo 'add_drivers+="xen-netfront xen-blkfront "' &gt; /etc/dracut.conf.d/xen.conf
KERNEL_VERSION=$(rpm -q kernel --qf '%{V}-%{R}.%{arch}\n'|head -n1)
dracut -f /boot/initramfs-$KERNEL_VERSION.img $KERNEL_VERSION
</code></pre>]]></content:encoded>
            <category>kylin</category>
            <category>cvm</category>
        </item>
        <item>
            <title><![CDATA[银河麒麟v10 aarch64机器构建percona-xtrabackup-80 rpm包]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/07/21/kylin-v10-aarch64-build-percona-xtrabackup-80-rpm</link>
            <guid>https://itxx00.github.io/notes/blog/2021/07/21/kylin-v10-aarch64-build-percona-xtrabackup-80-rpm</guid>
            <pubDate>Wed, 21 Jul 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[如何自己构建aarch64 xtrabackup rpm]]></description>
            <content:encoded><![CDATA[<h2 id="1-环境准备">1 环境准备</h2>
<pre><code>
yum install cmake3 openssl-devel libaio libaio-devel automake autoconf bison libtool ncurses-devel \
    libgcrypt-devel libev-devel libcurl-devel zlib-devel vim-common readline-devel python-sphinx rpm-build
</code></pre>
<h2 id="2-获取最新srpm包">2 获取最新SRPM包</h2>
<pre><code># 查看需要下载的版本
https://repo.percona.com/yum/release/8/SRPMS/
#如：
wget https://repo.percona.com/yum/release/8/SRPMS/percona-xtrabackup-80-8.0.25-17.1.generic.src.rpm
</code></pre>
<h2 id="3-build-rpm">3 BUILD RPM</h2>
<pre><code>rpm -ivh percona-xtrabackup-80-8.0.25-17.1.generic.src.rpm
cd ~/rpmbuild
rpmbuild -bb --nodebuginfo SPECS/percona-xtrabackup.spec
</code></pre>
<h2 id="over">OVER</h2>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[UOS arm64机器build percona-xtrabackup-80 deb包]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/07/21/uos-arm64-build-percona-xtrabackup-80</link>
            <guid>https://itxx00.github.io/notes/blog/2021/07/21/uos-arm64-build-percona-xtrabackup-80</guid>
            <pubDate>Wed, 21 Jul 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[uos如何快速构建xtrabackup deb]]></description>
            <content:encoded><![CDATA[<h2 id="1-系统环境">1 系统环境</h2>
<pre><code>root@VM-0-14-linux:~# cat /etc/os-release
PRETTY_NAME="uos 20"
NAME="uos"
VERSION_ID="20"
VERSION="20"
ID=uos
HOME_URL="https://www.chinauos.com/"
BUG_REPORT_URL="http://bbs.chinauos.com"

root@VM-0-14-linux:~# uname -a
Linux VM-0-14-linux 4.19.0-arm64-server #1635 SMP Mon Jan 13 16:07:12 CST 2020 aarch64 GNU/Linux

root@VM-0-14-linux:~# cat /etc/debian_version
10.1
root@VM-0-14-linux:~#

</code></pre>
<h2 id="2-配置perconca官方apt源">2 配置perconca官方apt源</h2>
<pre><code>wget https://repo.percona.com/apt/percona-release_latest.buster_all.deb
dpkg -i percona-release_latest.buster_all.deb
# 修改脚本中两个变量
vi /usr/bin/percona-release
CODENAME=buster
OS_VER=buster
# 开启perconca源
percona-release enable-only tools release
</code></pre>
<h2 id="3-build">3 BUILD</h2>
<pre><code># 安装依赖
apt-get build-dep percona-xtrabackup-80
# 构建
apt-get source --compile percona-xtrabackup-80
</code></pre>
<h2 id="over">OVER</h2>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[how to build a static tmux bin]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/06/30/build-tmux-static</link>
            <guid>https://itxx00.github.io/notes/blog/2021/06/30/build-tmux-static</guid>
            <pubDate>Wed, 30 Jun 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[build-tmux-static.sh]]></description>
            <content:encoded><![CDATA[<p>build-tmux-static.sh</p>
<pre><code>#!/bin/bash
TARGETDIR=$1
if [ "$TARGETDIR" = "" ]; then
TARGETDIR=$(python -c 'import os; print os.path.realpath("local")')
fi
mkdir -p $TARGETDIR

libevent() {
  curl -LO https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz
  tar -zxvf libevent-2.0.22-stable.tar.gz
  cd libevent-2.0.22-stable
  ./configure --prefix=$TARGETDIR &amp;&amp; make &amp;&amp; make install
  cd ..
}

ncurses() {
  curl -LO https://ftp.gnu.org/pub/gnu/ncurses/ncurses-6.0.tar.gz
  tar zxvf ncurses-6.0.tar.gz
  cd ncurses-6.0

  ./configure --with-termlib --prefix $TARGETDIR \
              --with-default-terminfo-dir=/usr/share/terminfo \
              --with-terminfo-dirs="/etc/terminfo:/lib/terminfo:/usr/share/terminfo" \
              --enable-pc-files \
              --with-pkg-config-libdir=$TARGETDIR/lib/pkgconfig \
  &amp;&amp; make &amp;&amp; make install
  cd ..
}

tmux() {
  curl -LO https://github.com/tmux/tmux/releases/download/3.2a/tmux-3.2a.tar.gz
  tar zxvf tmux-3.2a.tar.gz
  cd tmux-3.2a
  PKG_CONFIG_PATH=$TARGETDIR/lib/pkgconfig ./configure --enable-static --prefix=$TARGETDIR &amp;&amp; make &amp;&amp; make install
  cd ..
  cp $TARGETDIR/bin/tmux .
}

libevent
ncurses
tmux
</code></pre>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[使用dozzle通过web界面实时查看docker日志]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/06/08/dozzle-realtime-docker-log-view</link>
            <guid>https://itxx00.github.io/notes/blog/2021/06/08/dozzle-realtime-docker-log-view</guid>
            <pubDate>Tue, 08 Jun 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[如何通过web界面查看docker容器日志]]></description>
            <content:encoded><![CDATA[<h2 id="1-运行dozzle">1 运行dozzle</h2>
<pre><code>docker run --detach --volume=/var/run/docker.sock:/var/run/docker.sock --net host  amir20/dozzle --addr 127.0.0.1:8080  --base /dockerlogs
</code></pre>
<h2 id="2-反向代理">2 反向代理</h2>
<pre><code>server {
    listen 80;
    server_name xxx;
    client_max_body_size 1G;
    add_header  Access-Control-Allow-Origin "https://xxx";
    add_header  Access-Control-Allow-Methods "GET, POST, OPTIONS";
    add_header  Access-Control-Allow-Headers "Origin, Authorization, Accept";
    add_header  Access-Control-Allow-Credentials true;

    location ^~ /dockerlogs {
        proxy_pass http://localhost:8080;
    }
}
</code></pre>
<h2 id="3-访问">3 访问</h2>
<p><a href="http://x.x.x.x/dockerlogs">http://x.x.x.x/dockerlogs</a></p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[中标麒麟系统ansible执行yum模块报错的问题分析]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/03/22/neokylin-ansible-yum-module-not-work</link>
            <guid>https://itxx00.github.io/notes/blog/2021/03/22/neokylin-ansible-yum-module-not-work</guid>
            <pubDate>Mon, 22 Mar 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>在使用中标麒麟V7Update6版本时，遇到了一个ansible执行报错的问题</p>
</blockquote>
<h2 id="问题现象">问题现象</h2>
<p>在中标麒麟（neokylin）系统中部署某服务，使用到了ansible，但是执行时发现有yum模块的task报错如下：</p>
<pre><code>TASK [common : Install basic rpms] **************************************************************************
fatal: [node01]: FAILED! =&gt; {"changed": false, "msg": ["Could not detect which major revision of yum is in use, which is required to determine module backend.", "You can manually specify use_backend to tell the module whether to use the yum (yum3) or dnf (yum4) backend})"]}
</code></pre>
<p>报错为yum模块无法判断出系统的yum版本，提示需要手工执行yum的use_backend参数。同样的task在原生RHEL7系统执行没有遇到任何问题，看样子调入了中标麒麟的某个坑里。</p>
<h2 id="问题分析">问题分析</h2>
<p>根据报错，很明确是因为ansible无法自动判断出系统使用的yum版本导致，我们知道当ansible中yum模块不指定use_backend参数时，将尝试自动判断，而ansible的setup模块可以获取对应的必要信息，
其中一个变量ansible_pkg_mgr及对应yum后端模块，接下来我们执行setup模块输出ansible_pkg_mgr变量来验证下我们的判断：</p>
<pre><code># ansible -i hosts node01 -m setup -a "filter=ansible_pkg_mgr"
node01 | SUCCESS =&gt; {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}
</code></pre>
<p>果然没有办法获取到ansible_pkg_mgr变量，先看下系统版本信息:</p>
<pre><code>~]# cat /etc/neokylin-release
NeoKylin Linux Advanced Server release V7Update6 (Chromium)
</code></pre>
<p>接下来根据报错提示信息找到ansible相关代码，在yum.py中，相关代码如下：
ansible/plugins/action/yum.py</p>
<pre><code>        if module not in ["yum", "yum4", "dnf"]:
            facts = self._execute_module(module_name="setup", module_args=dict(filter="ansible_pkg_mgr", gather_subset="!all"), task_vars=task_vars)
            display.debug("Facts %s" % facts)
            module = facts.get("ansible_facts", {}).get("ansible_pkg_mgr", "auto")
            if (not self._task.delegate_to or self._task.delegate_facts) and module != 'auto':
                result['ansible_facts'] = {'pkg_mgr': module}

        if module != "auto":

            if module == "yum4":
                module = "dnf"

            if module not in self._shared_loader_obj.module_loader:
                result.update({'failed': True, 'msg': "Could not find a yum module backend for %s." % module})
            else:
                # run either the yum (yum3) or dnf (yum4) backend module
                new_module_args = self._task.args.copy()
                if 'use_backend' in new_module_args:
                    del new_module_args['use_backend']

                display.vvvv("Running %s as the backend for the yum action plugin" % module)
                result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val))
                # Now fall through to cleanup
        else:
            result.update(
                {
                    'failed': True,
                    'msg': ("Could not detect which major revision of yum is in use, which is required to determine module backend.",
                            "You can manually specify use_backend to tell the module whether to use the yum (yum3) or dnf (yum4) backend})"),
                }
            )
            # Now fall through to cleanup

</code></pre>
<p>如代码所示，当执行yum未指定use_backend参数时，ansible会执行setup模块并根据ansible_pkg_mgr来自动判断yum的版本，获取不到则会报错，继续看下该参数的获取过程，找到pkg_mgr.py，关键代码如下：</p>
<p>ansible/module_utils/facts/system/pkg_mgr.py</p>
<pre><code>    def collect(self, module=None, collected_facts=None):
        facts_dict = {}
        collected_facts = collected_facts or {}

        pkg_mgr_name = 'unknown'
        for pkg in PKG_MGRS:
            if os.path.exists(pkg['path']):
                pkg_mgr_name = pkg['name']

        # Handle distro family defaults when more than one package manager is
        # installed or available to the distro, the ansible_fact entry should be
        # the default package manager officially supported by the distro.
        if collected_facts['ansible_os_family'] == "RedHat":
            pkg_mgr_name = self._check_rh_versions(pkg_mgr_name, collected_facts)
... ...

 def _check_rh_versions(self, pkg_mgr_name, collected_facts):
        if collected_facts['ansible_distribution'] == 'Fedora':
            if os.path.exists('/run/ostree-booted'):
                return "atomic_container"
            try:
                if int(collected_facts['ansible_distribution_major_version']) &lt; 23:
                    for yum in [pkg_mgr for pkg_mgr in PKG_MGRS if pkg_mgr['name'] == 'yum']:
                        if os.path.exists(yum['path']):
                            pkg_mgr_name = 'yum'
                            break
                else:
                    for dnf in [pkg_mgr for pkg_mgr in PKG_MGRS if pkg_mgr['name'] == 'dnf']:
                        if os.path.exists(dnf['path']):
                            pkg_mgr_name = 'dnf'
                            break
            except ValueError:
                # If there's some new magical Fedora version in the future,
                # just default to dnf
                pkg_mgr_name = 'dnf'
        elif collected_facts['ansible_distribution'] == 'Amazon':
            pkg_mgr_name = 'yum'
        else:
            # If it's not one of the above and it's Red Hat family of distros, assume
            # RHEL or a clone. For versions of RHEL &lt; 8 that Ansible supports, the
            # vendor supported official package manager is 'yum' and in RHEL 8+
            # (as far as we know at the time of this writing) it is 'dnf'.
            # If anyone wants to force a non-official package manager then they
            # can define a provider to either the package or yum action plugins.
            if int(collected_facts['ansible_distribution_major_version']) &lt; 8:
                pkg_mgr_name = 'yum'
            else:
                pkg_mgr_name = 'dnf'
        return pkg_mgr_name

</code></pre>
<p>以上代码可以看到当判断系统为红帽系，则会继续判断系统版本信息，当主版本号小于8则使用yum，否则使用dnf，这里我们初步判断为麒麟对系统做了某些修改导致无法获取到主版本号。先执行setup获取发行版代号验证下是否执行了上述逻辑：</p>
<pre><code># ansible -i hosts node01 -m setup -a "filter=ansible_distribution"
node01 | SUCCESS =&gt; {
    "ansible_facts": {
        "ansible_distribution": "RedHat",
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}

# ansible -i hosts node01 -m setup -a "filter=ansible_distribution_major_version"
node01 | SUCCESS =&gt; {
    "ansible_facts": {
        "ansible_distribution_major_version": "V7Update6",
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}
</code></pre>
<p>通过setup模块的输出结果可看到系统是判断为redhat发行版，但是通过ansible_distribution_major_version获取到的发行版主版本号为V7Update6,
而和上面判断yum版本的代码关联起来看就会发现问题所在，int(collected_facts['ansible_distribution_major_version']) &lt; 8 中，ansible_distribution_major_version 变量在其初始化的代码中对应为为distribution_version.split('.')[:2][0]的取值，而当系统中获取到的值是V7Update6时，该显然无法满足转换为int的要求。接下来看下V7Update6这个关键字的定义位置，根据经验系统版本相关信息应该在/etc/os-release中：</p>
<pre><code>~]# cat /etc/os-release
NAME="NeoKylin Linux Advanced Server"
VERSION="V7Update6 (Chromium)"
ID="neokylin"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="V7Update6"
PRETTY_NAME="NeoKylin Linux Advanced Server V7Update6 (Chromium)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:neokylin:enterprise_linux:V7Update6:GA:server"
HOME_URL="https://www.cs2c.com.cn/"
BUG_REPORT_URL="https://bugzilla.cs2c.com.cn/"

NEOKYLIN_BUGZILLA_PRODUCT="NeoKylin Linux Advanced Server 7"
NEOKYLIN_BUGZILLA_PRODUCT_VERSION=V7Update6
NEOKYLIN_SUPPORT_PRODUCT="NeoKylin Linux Advanced Server"
NEOKYLIN_SUPPORT_PRODUCT_VERSION="V7Update6"
</code></pre>
<p>这里果然可以看到VERSION_ID的值被定义为<code>V7Update6</code>，而系统原生发行版中该值是7，我们来看下os-release中对VERSION_ID参数的说明：</p>
<pre><code>man os-release
... ...

       VERSION_ID=
           A lower-case string (mostly numeric, no spaces or other characters outside of 0-9, a-z, ".",
           "_" and "-") identifying the operating system version, excluding any OS name information or
           release code name, and suitable for processing by scripts or usage in generated filenames. This
           field is optional. Example: "VERSION_ID=17" or "VERSION_ID=11.04".
... ...
</code></pre>
<p>根据man文档中的描述，VERSION_ID取值范围为全小写，通常为数值型，不应有空格或其他特殊字符，可包含的字符为0-9a-z._-,那么这里可以看到两个问题，
第一个问题是kylin的VERSION_ID不符合此描述，包含了大写字符，第二个问题是VERSION_ID可以包含a-z字母，但是通常是数值如17,11.04等。
但由于常见发行版都将此处处理为数值型，就导致ansible按照此约定俗成固化了其获取系统版本的方法，并试图将一个字符串转换为int，不能满足当VERSION_ID包含了字母的情况。</p>
<h2 id="验证结论">验证结论</h2>
<p>通过以上判断看到VERSION_ID是导致该问题现象的关键，那么我们可以尝试修改一下该参数值，再执行setup看看是否可以正常工作：</p>
<pre><code># grep VERSION_ID /etc/os-release
VERSION_ID="7"
</code></pre>
<p>这里我把VERSION_ID修改成了数字7，再执行setup观察ansible_pkg_mgr变量是否能获取到：</p>
<pre><code># ansible -i hosts node01 -m setup -a "filter=ansible_pkg_mgr"
node01 | SUCCESS =&gt; {
    "ansible_facts": {
        "ansible_pkg_mgr": "yum",
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false
}
</code></pre>
<p>可以看到，修改os-release中VERSION_ID为纯数值后，setup就可以正常判断到系统版本，进而可以获取到正确的yum版本了。
通过以上可以看到操作系统中即便是一些不起眼的细枝末节，处理不当也可能引发"连锁反应"。</p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[bashrc与profile的加载顺序]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/02/24/bash-rc-profile-exec-order</link>
            <guid>https://itxx00.github.io/notes/blog/2021/02/24/bash-rc-profile-exec-order</guid>
            <pubDate>Wed, 24 Feb 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[看下bashrc和profile的执行顺序到底是什么样的]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>在使用bashrc和profile设置环境变量时，如果多个地方都有同一个变量的设置，则需要注意不同配置文件的加载顺序问题</p>
</blockquote>
<h2 id="背景">背景</h2>
<p>如果加载顺序没弄明白，有可能会在使用过程中遇到各种困扰，比如为什么设置了profile但是环境变量不生效？为什么变量ssh后获取的不一样？下面我们以CentOS7系统为例，通过一个简单的小实验来观察下到底bash的几个配置文件加载顺序是怎样的。</p>
<p>我们知道可以用来设置环境变量的文件常用的有以下几个：</p>
<ul>
<li>/etc/profile</li>
<li>/etc/profile.d/*.sh</li>
<li>/etc/bashrc</li>
<li>~/.bash_profile</li>
<li>~/.bashrc</li>
</ul>
<p>而不同的文件加载时机又分为login shell和non-login shell两种情况。这两种情况需要区分对待，及不同的文件要在对应场景下才能生效。假设有一个相同的变量设置出现在各个文件里面，通过对不同文件的变量值进行差异设置即可观察出各个配置的加载优先级和生效情况。</p>
<h2 id="实验">实验</h2>
<p>先写入各个配置文件如下：</p>
<pre><code># tail -n1 /etc/profile /etc/bashrc /etc/profile.d/well.sh ~/.bash_profile ~/.bashrc
==&gt; /etc/profile &lt;==
export WELL=etc-profile

==&gt; /etc/bashrc &lt;==
export WELL=etc-bashrc

==&gt; /etc/profile.d/well.sh &lt;==
export WELL=etc-profile-d

==&gt; /root/.bash_profile &lt;==
export WELL=home-bash-profile

==&gt; /root/.bashrc &lt;==
export WELL=home-bashrc
</code></pre>
<p>接下来开始观察，需要注意的是每次修改配置之后新开shell重新加载环境配置：</p>
<pre><code>[root@localhost ~]# echo $WELL
home-bash-profile
[root@localhost ~]# ssh localhost 'echo $WELL'
home-bashrc
[root@localhost ~]#


[root@localhost ~]# sed -i '$d' ~/.bashrc
[root@localhost ~]# sed -i '$d' ~/.bash_profile
[root@localhost ~]#


[root@localhost ~]# echo $WELL
etc-bashrc
[root@localhost ~]# ssh localhost 'echo $WELL'
etc-bashrc
[root@localhost ~]#


[root@localhost ~]# sed -i '$d' /etc/bashrc


[root@localhost ~]# echo $WELL
etc-profile
[root@localhost ~]# ssh localhost 'echo $WELL'
etc-profile-d
[root@localhost ~]#

# 重新写入~/.bashrc后
[root@localhost ~]# echo $WELL
home-bashrc
[root@localhost ~]# ssh localhost 'echo $WELL'
etc-profile-d
[root@localhost ~]#


# 重新写入~/.bash_profile,去掉~/.bashrc后
[root@localhost ~]# echo $WELL
home-bash-profile
[root@localhost ~]# ssh localhost 'echo $WELL'
etc-profile-d
[root@localhost ~]#

</code></pre>
<p>需要注意的是以上测试是将变量放到每个配置末行，因为配置之间有互相加载的机制，如果放在其他位置则测试结果会不一样。</p>
<h2 id="结论">结论</h2>
<p>观察上面的结果，可以得出以下实验结论：</p>
<p>1 login shell会加载所有配置,优先级为~/.bash_profile ~/.bashrc /etc/bashrc /etc/profile /etc/profile.d</p>
<p>2 non-login shell时加载优先级为 ~/.bashrc /etc/bashrc /etc/profile.d</p>
<p>3 non-login shell不会加载的配置有 ~/.bash_profile /etc/profile</p>
<p>4 两种情况下都会加载的有~/.bashrc /etc/bashrc /etc/profile.d</p>
<p>那么如果我们需要在系统全局设置一个环境变量，要保证login shell和non-login shell都能表现一致，需要如何设置呢？</p>
<p>因为~/.bashrc为用户局部配置文件，不影响全局，而/etc/bashrc为系统内置文件不建议修改，如果是有全局环境变量需要设置建议放置到/etc/profile.d</p>
<p>over.</p>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[使用conventional-changelog和Strapdown.js为git仓库自动生成changelog html页面]]></title>
            <link>https://itxx00.github.io/notes/blog/2021/01/15/auto-create-changelog-html</link>
            <guid>https://itxx00.github.io/notes/blog/2021/01/15/auto-create-changelog-html</guid>
            <pubDate>Fri, 15 Jan 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[通过简单的工具组合为git项目生成简单的changelog html]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>一个项目的changelog对于使用者来说虽然不需要重点关注，但很重要</p>
</blockquote>
<h2 id="基本思路">基本思路</h2>
<p>通常软件产品对外发布时，我们需要提供一份changelog以告知使用者新版本所发生的变化，有两种方式可以产生需要的changelog内容， 一种是人工整理和编写，另外一种是通过工具实现自动化。这里介绍一种通过开源工具的组合快速实现自动生成的方法。</p>
<p>我们在开发过程中所有变更都会反映到git commit messages里面，git提交历史几乎可以反映软件的所有变更，基于此我们可以使用工具直接将git提交历史转化为changelog，再经过简单加工处理即可对外输出一个html页面。</p>
<h2 id="规范提交">规范提交</h2>
<p>这就要求在代码提交过程中我们的commit message要规范化，其中一种被广为认可的规范名为约定式提交。详细可参考<a href="https://www.conventionalcommits.org/zh-hans">约定式提交</a>
一个简单的提交类型参考如下：</p>
<ul>
<li><strong>build</strong>: 变更仅影响工具出包或者build环境等外部依赖问题</li>
<li><strong>ci</strong>: 对CI配置的变更</li>
<li><strong>docs</strong>: 仅文档内容变更</li>
<li><strong>feat</strong>: 新特性</li>
<li><strong>fix</strong>: bug修复</li>
<li><strong>perf</strong>: 无bug修复/无新特性，仅性能提升</li>
<li><strong>refactor</strong>: 无bug修复/无新特性/无性能提升，仅重构</li>
<li><strong>style</strong>: 仅代码风格更改</li>
<li><strong>test</strong>: 仅测试代码变更</li>
</ul>
<h2 id="提交转化为markdown">提交转化为markdown</h2>
<p>有了规范的提交记录，下面就可以通过工具实现提交记录到markdown的转化。这里介绍一个工具叫conventional-changelog，命令行版本使用方法如下：</p>
<pre><code># install
npm install -g conventional-changelog-cli
# generate changelog markdown file
cd your-git-repo-project-home
conventional-changelog -p angular -i CHANGELOG.md -s -r 0
</code></pre>
<p>示例中用到的参数：</p>
<ul>
<li>-i : 读入已有changelog文件</li>
<li>-p : 预设模板，可以是angular/atom/codemirror/ember/eslint/express/jquery/jscs/jshint</li>
<li>-s : 写到目标文件名和-i指定的文件同名</li>
<li>-r : 指定需要生成的release数量，0表示重新生成所有</li>
</ul>
<p>更多参数可以执行<code>conventional-changelog --help</code>查看。</p>
<h2 id="markdown转化为html">markdown转化为html</h2>
<p>这样我们就得到了一份名为CHANGELOG.md的历史变更记录文件，为markdown格式。接下来再通过另外一个工具名叫strapdown.js来自动生成html。</p>
<p>strapdown.js是一个js文件，不需要像上面生成markdown那样在server端生成，只需要在单个html页面中引入该js文件即可实现从markdown自动渲染出html页面。详细可参考<a href="https://strapdownjs.com/">strapdown.js</a></p>
<p>使用方法如下：</p>
<pre><code>cat &gt;changelog.html &lt;&lt;"EOF"
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;title&gt;XXX Changelog&lt;/title&gt;
&lt;meta charset="utf-8"&gt;
&lt;xmp theme="darkly" style="display:none;"&gt;
EOF

cat CHANGELOG.md &gt;&gt;changelog.html
cat &gt;&gt;changelog.html &lt;&lt;"EOF"
&lt;/xmp&gt;
&lt;script src="http://strapdownjs.com/v/0.2/strapdown.js"&gt;&lt;/script&gt;
&lt;/html&gt;
</code></pre>
<p>这样我们就通过拼接的方式生成了一份changelog.html。需要注意的是changlog内容中不能包含<code>&lt;/xmp&gt;</code>关键字。</p>
<p>over.</p>]]></content:encoded>
            <category>changelog</category>
            <category>conventional-changelog</category>
            <category>strapdown.js</category>
        </item>
        <item>
            <title><![CDATA[使用rpmrebuild修改rpm包内容]]></title>
            <link>https://itxx00.github.io/notes/blog/2020/04/07/change-rpm-file-using-rpmrebuild</link>
            <guid>https://itxx00.github.io/notes/blog/2020/04/07/change-rpm-file-using-rpmrebuild</guid>
            <pubDate>Tue, 07 Apr 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[一种rpm包的魔改方式]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>某些特殊紧急情况下... ...</p>
</blockquote>
<p>某些特殊紧急情况下没法等到重新从源码编译打包，手里只有一个打包好的rpm，但是里面内容需要在安装前就改掉，比如修改某个文件内容等，这个时候rpmrebuild命令可以派上用场。
rpmrebuild工作时会把rpm包内容释放到一个临时目录，如果需要修改rpm包里面的文件的话， 可以通过-m参数指定执行的命令，比如/bin/bash，这样就可以得到一个交互式的shell，
有了交互式shell想象空间就很大了，你可以在这个shell环境下对rpm包释放出来的文件任意修改，当退出这个shell时，rpmrebuild会把改动打包回新的rpm。
例如：</p>
<pre><code>rpmrebuild -m /bin/bash -np rpm/xxx.rpm
# 此时我们得到一个交互shell，
# 比如知道需要修改的文件名为aaa，可以这样操作：
find / -name aaa
# 尽情发挥吧，完了退出
ctrl+D
</code></pre>
<p>现在你就得到修改好内容之后的新rpm了。</p>]]></content:encoded>
            <category>bash</category>
            <category>rpm</category>
            <category>rpmrebuild</category>
        </item>
        <item>
            <title><![CDATA[python脚本解压gbk编码zip]]></title>
            <link>https://itxx00.github.io/notes/blog/2020/03/27/unzip-gbk-with-python</link>
            <guid>https://itxx00.github.io/notes/blog/2020/03/27/unzip-gbk-with-python</guid>
            <pubDate>Fri, 27 Mar 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>编码问题很烦人</p>
</blockquote>
<p>gbk编码的zip在linux下解压出来文件名会乱码，可以用下面脚本解压过程中转换下</p>
<pre><code>#!/usr/bin/env python2
# coding: utf-8

import os
import sys
import zipfile

f = zipfile.ZipFile(sys.argv[1],"r");
for n in f.namelist():
    try:
        u = n.decode("gbk")
    except:
        u = n
    p = os.path.dirname(u)
    if not p:
        continue
    if not os.path.exists(p):
        os.makedirs(p)
    d = file.read(n)
    if os.path.exists(u):
        continue
    with open(u, "w") as o:
        o.write(data)
</code></pre>]]></content:encoded>
            <category>bash</category>
            <category>python</category>
        </item>
        <item>
            <title><![CDATA[CentOS8安装后grub菜单增加windows入口]]></title>
            <link>https://itxx00.github.io/notes/blog/2020/03/12/centos8-bootmenu-add-windows</link>
            <guid>https://itxx00.github.io/notes/blog/2020/03/12/centos8-bootmenu-add-windows</guid>
            <pubDate>Thu, 12 Mar 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[默认安装完不会自动识别其他系统，需要手工添加]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>电脑双系统centos+windows，安装完centos8之后默认没有引导windows的入口，按照下面方法手搓即可。</p>
</blockquote>
<h2 id="1-启动进入centos">1 启动进入centos</h2>
<p>查看磁盘分区信息，如下：
<code>fdisk -l</code></p>
<pre><code># fdisk -l
Disk /dev/sda: 238.5 GiB, 256060514304 bytes, 500118192 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x297f5cef

Device     Boot     Start       End   Sectors   Size Id Type
/dev/sda1  *         2048 250058751 250056704 119.2G  7 HPFS/NTFS/exFAT
/dev/sda2       250058752 393418751 143360000  68.4G  7 HPFS/NTFS/exFAT
/dev/sda3       393418752 394442751   1024000   500M 83 Linux
/dev/sda4       394442752 500117503 105674752  50.4G  5 Extended
/dev/sda5       394444800 500117503 105672704  50.4G 83 Linux
</code></pre>
<p>通过fdisk结果看到windows第一个partion在sda1，对应grub的磁盘索引编号是hd0,1,接下来编辑grub配置文件，自定义配置路径：</p>
<pre><code> vi  /etc/grub.d/40_custom
</code></pre>
<p>配置示例如下：</p>
<pre><code> #!/bin/sh
 exec tail -n +3 $0
 # This file provides an easy way to add custom menu entries.  Simply type the
 # menu entries you want to add after this comment.  Be careful not to change
 # the 'exec tail' line above.

 menuentry "Windows" {
         set root=(hd0,1)
         chainloader +1
         }
</code></pre>
<p>保存并执行以下命令使自定义配置生效：</p>
<pre><code>grub2-mkconfig --output=/boot/grub2/grub.cfg
</code></pre>
<p>OVER.</p>]]></content:encoded>
            <category>os</category>
            <category>centos</category>
            <category>grub</category>
            <category>centos8</category>
        </item>
        <item>
            <title><![CDATA[shell style guide]]></title>
            <link>https://itxx00.github.io/notes/blog/2020/01/03/shell-standards</link>
            <guid>https://itxx00.github.io/notes/blog/2020/01/03/shell-standards</guid>
            <pubDate>Fri, 03 Jan 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>这里是一句长长的引言</p>
</blockquote>
<ul>
<li>Shell 编码规范</li>
</ul>
<h2 id="前言">前言</h2>
<p>与其它的编程规范一样，这里所讨论的不仅仅是编码格式美不美观的问题， 同时也讨论一些约定及编码标准。这份文档主要侧重于我们所普遍遵循的规则， 对于那些不是明确强制要求的，我们尽量避免提供意见。</p>
<h3 id="为什么要有编码规范">为什么要有编码规范</h3>
<p>编码规范对于程序员而言尤为重要，有以下几个原因：</p>
<ul>
<li>一个软件的生命周期中，80%的花费在于维护</li>
<li>几乎没有任何一个软件，在其整个生命周期中，均由最初的开发人员来维护</li>
<li>编码规范可以改善软件的可读性，可以让程序员尽快而彻底地理解新的代码</li>
<li>如果你将源码作为产品发布，就需要确任它是否被很好的打包并且清晰无误，一如你已构建的其它任何产品</li>
</ul>
<h3 id="编码规范原则">编码规范原则</h3>
<p>本文档中的准则致力于最大限度达到以下原则：</p>
<ul>
<li>正确性</li>
<li>可读性</li>
<li>可维护性</li>
<li>可调试性</li>
<li>一致性</li>
<li>美观</li>
</ul>
<p>尽管本文档涵盖了许多基础知识，但应注意的是，没有编码规范可以为我们回答所有问题，开发人员始终需要再编写完代码后，对上述原则做出正确的判断。</p>
<h3 id="代码规范等级定义">代码规范等级定义</h3>
<ul>
<li><strong>可选（Optional）</strong>：用户可参考，自行决定是否采用；</li>
<li><strong>推荐（Preferable）</strong>：用户理应采用，但如有特殊情况，可以不采用；</li>
<li><strong>必须（Mandatory）</strong>：用户必须采用（除非是少数非常特殊的情况，才能不采用）；</li>
</ul>
<p><strong>注：</strong> 未明确指明的则默认为 <strong>必须（Mandatory）</strong></p>
<h3 id="本文档参考">本文档参考</h3>
<p>主要参考如下文档:</p>
<ul>
<li><a href="https://google.github.io/styleguide/shell.xml" title="Google Shell Style Guide">Google Shell Style Guide</a></li>
<li><a href="https://wiki.bash-hackers.org/scripting/style" title="Scripting with style">Bash Hackers Wiki</a></li>
</ul>
<h2 id="源文件">源文件</h2>
<h3 id="基础">基础</h3>
<h4 id="使用场景">使用场景</h4>
<p>仅建议Shell用作相对简单的实用工具或者包装脚本。因此单个shell脚本内容不宜太过复杂。</p>
<p>在选择何时使用shell脚本时时应遵循以下原则：</p>
<ul>
<li>如主要用于调用其他工具且需处理的数据量较少，则shell是一个选择</li>
<li>如对性能十分敏感，则更推荐选择其他语言，而非shell</li>
<li>如需处理相对复杂的数据结构，则更推荐选择其他语言，而非shell</li>
<li>如脚本内容逐渐增长且有可能出现继续增长的趋势，请尽早使用其他语言重写</li>
</ul>
<h4 id="文件名">文件名</h4>
<p>可执行文件不建议有扩展名，库文件必须使用 <strong>.sh</strong> 作为扩展名，且应是不可执行的。</p>
<p>执行一个程序时，无需知道其编写语言，且shell脚本并不要求具有扩展名，所以更倾向可执行文件没有扩展名。</p>
<p>而库文件知道其编写语言十分重要，使用 <strong>.sh</strong> 作为特定语言后缀的扩展名，可以和其他语言编写的库文件加以区分。</p>
<p>文件名要求全部小写, 可以包含下划线 <code>_</code> 或连字符 <code>-</code>, 建议可执行文件使用连字符，库文件使用下划线。</p>
<p>正例:</p>
<pre><code>my-useful-bin
my_useful_libraries.sh
myusefullibraries.sh
</code></pre>
<p>反例：</p>
<pre><code>My_Useful_Bin
myUsefulLibraries.sh
</code></pre>
<h4 id="文件编码">文件编码</h4>
<p>源文件编码格式为<strong>UTF-8</strong>。
避免不同操作系统对文件换行处理的方式不同，一律使用<code>LF</code>。</p>
<h4 id="单行长度">单行长度</h4>
<p>每行最多不超过120个字符。每行代码最大长度限制的根本原因是过长的行会导致阅读障碍，使得缩进失效。</p>
<p>除了以下两种情况例外：</p>
<ul>
<li>导入模块语句</li>
<li>注释中包含的URL</li>
</ul>
<p>如出现长度必须超过120个字符的字符串，应尽量使用here document或者嵌入的换行符等合适的方法使其变短。</p>
<p>示例：</p>
<pre><code># DO use 'here document's
cat &lt;&lt;END;
I am an exceptionally long
string.
END

# Embedded newlines are ok too
long_string="I am an exceptionally
  long string."
</code></pre>
<h4 id="空白字符">空白字符</h4>
<p>除了在行结束使用换行符，空格是源文件中唯一允许出现的空白字符。</p>
<ul>
<li>字符串中的非空格空白字符，使用转义字符</li>
<li>不允许行前使用tab缩进，如果使用tab缩进，必须设置1个tab为4个空格</li>
<li>不应在行尾出现没有意义的空白字符</li>
</ul>
<h4 id="垃圾清理--推荐--">垃圾清理<sup>  <em>推荐</em>  </sup></h4>
<p>对从来没有用到的或者被注释的方法、变量等要坚决从代码中清理出去，避免过多垃圾造成干扰。</p>
<h3 id="结构">结构</h3>
<h4 id="使用bash">使用bash</h4>
<p>Bash 是唯一被允许使用的可执行脚本shell。</p>
<p>可执行文件必须以 <code>#!/bin/bash</code> 开始。请使用 <code>set</code> 来设置shell的选项，使得用 <code>bash &lt;script_name&gt;</code> 调用你的脚本时不会破坏其功能。</p>
<p>限制所有的可执行shell脚本为bash使得我们安装在所有计算机中的shell语言保持一致性。
正例：</p>
<pre><code>#!/bin/bash
set -e
</code></pre>
<p>反例：</p>
<pre><code>#!/bin/sh -e
</code></pre>
<h4 id="许可证�或版权信息--推荐--">许可证或版权信息<sup>  <em>推荐</em>  </sup></h4>
<p>许可证与版权信息需放在源文件的起始位置。例如：</p>
<pre><code>#
# Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
# in compliance with the License. You may obtain a copy of the License at
#
# https://opensource.org/licenses/BSD-3-Clause
#
# Unless required by applicable law or agreed to in writing, software distributed
# under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
# CONDITIONS OF ANY KIND, either express or implied. See the License for the
# specific language governing permissions and limitations under the License.
#

</code></pre>
<h4 id="缩进">缩进</h4>
<h5 id="块缩进">块缩进</h5>
<p>每当开始一个新的块，缩进增加4个空格（不能使用\t字符来缩进）。当块结束时，缩进返回先前的缩进级别。缩进级别适用于代码和注释。</p>
<pre><code>main() {
    # 缩进4个空格
    say="hello"
    flag=0
    if [[ $flag = 0 ]]; then
        # 缩进4个空格
        echo "$say"
    fi
</code></pre>
<h5 id="管道">管道</h5>
<p>如果一行容不下整个管道操作，那么请将整个管道操作分割成每行一个管段。</p>
<p>如果一行容得下整个管道操作，那么请将整个管道操作写在同一行，管道左右应有空格。</p>
<p>否则，应该将整个管道操作分割成每行一段，管道操作的下一部分应该将管道符放在新行并且缩进4个空格。这适用于管道符 <code>|</code> 以及逻辑运算 <code>||</code> 和 <code>&amp;&amp;</code> 。
正例：</p>
<pre><code># 单行管道连接，管道左右空格
command1 | command2

# 长命令管道换行连接，管道放置于下一个命令开头，缩进4个空格
command1 \
    | command2 \
    | command3 \
    | command4
</code></pre>
<p>反例：</p>
<pre><code># 管道左右无空格
command1|command2

# 换行连接管道放置于行末
command1 | \
    command2 | \
    command3 | \
    command4
</code></pre>
<h5 id="循环">循环</h5>
<p>请将 <code>; do</code> , <code>; then</code> 和 <code>while</code> , <code>for</code> , <code>if</code> 放在同一行。</p>
<p>shell中的循环略有不同，但是我们遵循跟声明函数时的大括号相同的原则。即：
<code>; do</code> , <code>; then</code> 应该和 while/for/if 放在同一行。
else 应该单独一行。
结束语句应该单独一行且跟开始语句缩进对齐。</p>
<p>正例：</p>
<pre><code>for dir in ${dirs_to_cleanup}; do
    if [[ -d "${dir}/${BACKUP_SID}" ]]; then
        log_date "Cleaning up old files in ${dir}/${BACKUP_SID}"
        rm "${dir}/${BACKUP_SID}/"*
        if [[ "$?" -ne 0 ]]; then
            error_message
        fi
    else
        mkdir -p "${dir}/${BACKUP_SID}"
        if [[ "$?" -ne 0 ]]; then
            error_message
        fi
    fi
done
</code></pre>
<p>反例：</p>
<pre><code>function getBatchName()
{
    batch_name="batch"
    if [[ "$input5"x == *$batch_name* ]]
    then
        batch_name=$input5
    else if [[ "$input6"x == *$batch_name* ]]
    then
        batch_name=$input6
    else if [[ "$input7"x == *$batch_name* ]]
    then
        batch_name=$input7
        fi
        fi
    fi
}
</code></pre>
<h5 id="case语句">case语句</h5>
<p>通过4个空格缩进可选项。
可选项中的多个命令应该被拆分成多行，模式表达式、操作和结束符 <code>;;</code> 在不同的行。
匹配表达式比 case 和 esac 缩进一级。多行操作要再缩进一级。
模式表达式前面不应该出现左括号。避免使用 <code>;&amp;</code> 和 <code>;;&amp;</code> 符号。
示例：</p>
<pre><code>case "${expression}" in
    a)
        variable="..."
        some_command "${variable}" "${other_expr}" ...
        ;;
    absolute)
        actions="relative"
        another_command "${actions}" "${other_expr}" ...
        ;;
    *)
        error "Unexpected expression '${expression}'"
        ;;
esac
</code></pre>
<p>只要整个表达式可读，简单的单行命令可以跟模式和 ;; 写在同一行。当单行容不下操作时，请使用多行的写法。
单行示例：</p>
<pre><code>verbose='false'
aflag=''
bflag=''
files=''
while getopts 'abf:v' flag; do
    case "${flag}" in
        a) aflag='true' ;;
        b) bflag='true' ;;
        f) files="${OPTARG}" ;;
        v) verbose='true' ;;
        *) error "Unexpected option ${flag}" ;;
    esac
done
</code></pre>
<h4 id="函数位置">函数位置</h4>
<p>将文件中所有的函数统一放在常量下面。不要在函数之间隐藏可执行代码。</p>
<p>如果你有函数，请将他们统一放在文件头部。只有includes， set 声明和常量设置可能在函数声明之前完成。不要在函数之间隐藏可执行代码。如果那样做，会使得代码在调试时难以跟踪并出现意想不到的结果。</p>
<h4 id="主函数main">主函数main</h4>
<p>对于包含至少了一个其他函数的足够长的脚本，建议定义一个名为 main 的函数。对于功能简单的短脚本， main函数是没有必要的。</p>
<p>为了方便查找程序的入口位置，将主程序放入一个名为 main 的函数中，作为最底部的函数。这使其和代码库的其余部分保持一致性，同时允许你定义更多变量为局部变量（如果主代码不是一个函数就不支持这种做法）。
文件中最后的非注释行应该是对 main 函数的调用：</p>
<pre><code>main "$@"
</code></pre>
<h4 id="注释">注释</h4>
<p>代码注释的基本原则：</p>
<ul>
<li>注释应能使代码更加明确</li>
<li>避免注释部分的过度修饰</li>
<li>保持注释部分简单、明确</li>
<li>在编码以前就应开始写注释</li>
<li>注释应说明设计思路而不是描述代码的行为</li>
</ul>
<p>注释与其周围的代码在同一缩进级别，#号与注释文本间需保持一个空格以和注释代码进行区分。</p>
<h5 id="文件头">文件头</h5>
<p>每个文件的开头是其文件内容的描述。除版权声明外，每个文件必须包含一个顶层注释，对其功能进行简要概述。</p>
<p>例如：</p>
<pre><code>#!/bin/bash
#
# Perform hot backups of databases.
</code></pre>
<h5 id="功能注释">功能注释</h5>
<p>主体脚本中除简洁明了的函数外都必须带有注释。库文件中所有函数无论其长短和复杂性都必须带有注释。</p>
<p>这使得其他人通过阅读注释即可学会如何使用你的程序或库函数，而不需要阅读代码。</p>
<p>所有的函数注释应该包含：</p>
<ul>
<li>函数的描述</li>
<li>全局变量的使用和修改</li>
<li>使用的参数说明</li>
<li>返回值，而不是上一条命令运行后默认的退出状态</li>
</ul>
<p>例如：</p>
<pre><code>#!/bin/bash
#
# Perform hot backups of databases.

export PATH='/usr/sbin/bin:/usr/bin:/usr/local/bin'

#######################################
# Cleanup files from the backup dir
# Globals:
#   BACKUP_DIR
#   BACKUP_SID
# Arguments:
#   None
# Returns:
#   None
#######################################
cleanup() {
    ...
}
</code></pre>
<h5 id="实现部分的注释">实现部分的注释</h5>
<p>注释你代码中含有技巧、不明显、有趣的或者重要的部分。</p>
<p>这部分遵循代码注释的基本原则即可。不要注释所有代码。如果有一个复杂的不易理解的逻辑，请进行简单的注释。</p>
<h5 id="todo注释">TODO注释</h5>
<p>对那些临时的, 短期的解决方案, 或已经够好但仍不完美的代码使用 TODO 注释.</p>
<p>TODO 注释要使用全大写的字符串 TODO, 在随后的圆括号里写上你的名字,邮件地址, bug ID, 或其它身份标识和与这一 TODO 相关的 issue。
主要目的是让添加注释的人 (也是可以请求提供更多细节的人) 可根据规范的TODO 格式进行查找。
添加 TODO 注释并不意味着你要自己来修正,因此当你加上带有姓名的 TODO 时, 一般都是写上自己的名字。</p>
<p>这与<strong>C++ Style Guide</strong>中的约定相一致。</p>
<p>例如：</p>
<pre><code># TODO(mrmonkey): Handle the unlikely edge cases (bug ####)
# TODO(--bug=123456): remove the "Last visitors" feature
</code></pre>
<h2 id="命名">命名</h2>
<h3 id="函数名">函数名</h3>
<p>使用小写字母，并用下划线分隔单词。使用双冒号 <code>::</code> 分隔包名。函数名之后必须有圆括号。</p>
<p>如果你正在写单个函数，请用小写字母来命名，并用下划线分隔单词。如果你正在写一个包，使用双冒号 <code>::</code> 来分隔包名。
函数名和圆括号之间没有空格，大括号必须和函数名位于同一行。
当函数名后存在 <code>()</code> 时，关键词 function 是多余的，建议不带 function 的写法，但至少做到同一项目内风格保持一致。
正例：</p>
<pre><code># Single function
my_func() {
  ...
}

# Part of a package
mypackage::my_func() {
  ...
}
</code></pre>
<p>反例：</p>
<pre><code>function my_func
{
    ...
}
</code></pre>
<h3 id="变量名">变量名</h3>
<p>规则同函数名一致。</p>
<p>循环中的变量名应该和正在被循环的变量名保持相似的名称。
示例：</p>
<pre><code>for zone in ${zones}; do
    something_with "${zone}"
done
</code></pre>
<h3 id="常量和环境变量名">常量和环境变量名</h3>
<p>全部大写，用下划线分隔，声明在文件的顶部。</p>
<p>常量和任何导出到环境中的变量都应该大写。
示例：</p>
<pre><code># Constant
readonly PATH_TO_FILES='/some/path'

# Both constant and environment
declare -xr BACKUP_SID='PROD'
</code></pre>
<p>有些情况下首次初始化及常量（例如，通过getopts），因此，在getopts中或基于条件来设定常量是可以的，但之后应该立即设置其为只读。
值得注意的是，在函数中使用 declare 对全局变量无效，所以推荐使用 readonly 和 export 来代替。
示例：</p>
<pre><code>VERBOSE='false'
while getopts 'v' flag; do
  case "${flag}" in
    v) VERBOSE='true' ;;
  esac
done
readonly VERBOSE
</code></pre>
<h3 id="只读变量">只读变量</h3>
<p>使用 readonly 或者 declare -r 来确保变量只读。</p>
<p>因为全局变量在shell中广泛使用，所以在使用它们的过程中捕获错误是很重要的。当你声明了一个变量，希望其只读，那么请明确指出。
示例：</p>
<pre><code>zip_version="$(dpkg --status zip | grep Version: | cut -d ' ' -f 2)"
if [[ -z "${zip_version}" ]]; then
  error_message
else
  readonly zip_version
fi
</code></pre>
<h3 id="局部变量">局部变量</h3>
<p>每次只声明一个变量,不要使用组合声明，比如<code>a=1 b=2</code>;</p>
<p>使用 local 声明特定功能的变量。声明和赋值应该在不同行。</p>
<p>必须使用 local 来声明局部变量，以确保其只在函数内部和子函数中可见。这样可以避免污染全局名称空间以及避免无意中设置可能在函数外部具有重要意义的变量。</p>
<p>当使用命令替换进行赋值时，变量声明和赋值必须分开。因为内建的 local 不会从命令替换中传递退出码。
正例：</p>
<pre><code>my_func2() {
    local name="$1"
    # 命令替换赋值，变量声明和赋值需放到不同行:
    local my_var
    my_var="$(my_func)" || return
    ...
}
</code></pre>
<p>反例：</p>
<pre><code>my_func2() {
    # 禁止以下写法: $? 将获取到'local'指令的返回值, 而非 my_func
    local my_var="$(my_func)"
    [[ $? -eq 0 ]] || return

    ...
}
</code></pre>
<h2 id="异常与日志">异常与日志</h2>
<h3 id="异常">异常</h3>
<p>使用shell返回值来返回异常，并根据不同的异常情况返回不同的值。</p>
<h3 id="日志">日志</h3>
<p>所有的错误信息都应被导向到STDERR，这样将有利于出现问题时快速区分正常输出和异常输出。</p>
<p>建议使用与以下函数类似的方式来打印正常和异常输出：</p>
<pre><code>err() {
    echo "[$(date +'%FT%T%z')]: $@" &gt;&amp;2
}

if ! do_something; then
    err "Unable to do_something"
    exit "${E_DID_NOTHING}"
fi
</code></pre>
<h2 id="编程实践--持续分类并完善--">编程实践<sup>  <em>持续分类并完善</em>  </sup></h2>
<h3 id="变量扩展---推荐--">变量扩展 <sup>  <em>推荐</em>  </sup></h3>
<p>通常情况下推荐为变量加上大括号如 <code>"${var}"</code> 而不是 <code>"$var"</code> ，但具体也要视情况而定。</p>
<p>以下按照优先顺序列出建议：</p>
<ul>
<li>与现有代码保持一致</li>
<li>单字符变量在特定情况下才需要被括起来</li>
<li>使用引号引用变量，参考下一节：变量引用</li>
</ul>
<p>详细示例如下：
正例：</p>
<pre><code># 位置变量和特殊变量，可以不用大括号:
echo "Positional: $1" "$5" "$3"
echo "Specials: !=$!, -=$-, _=$_. ?=$?, #=$# *=$* @=$@ \$=$$ ..."

# 当位置变量大于等于10，则必须有大括号:
echo "many parameters: ${10}"

# 当出现歧义时，必须有大括号:
# Output is "a0b0c0"
set -- a b c
echo "${1}0${2}0${3}0"

# 使用变量扩展赋值时，必须有大括号：
DEFAULT_MEM=${DEFUALT_MEM:-"-Xms2g -Xmx2g -XX:MaxDirectMemorySize=4g"}

# 其他常规变量的推荐处理方式:
echo "PATH=${PATH}, PWD=${PWD}, mine=${some_var}"
while read f; do
    echo "file=${f}"
done &lt; &lt;(ls -l /tmp)
</code></pre>
<p>反例：</p>
<pre><code># 无引号, 无大括号, 特殊变量，单字符变量
echo a=$avar "b=$bvar" "PID=${$}" "${1}"

# 无大括号产生歧义场景：以下会被解析为 "${1}0${2}0${3}0",
# 而非 "${10}${20}${30}
set -- a b c
echo "$10$20$30"
</code></pre>
<h4 id="变量引用---推荐--">变量引用 <sup>  <em>推荐</em>  </sup></h4>
<p>变量引用通常情况下应遵循以下原则：</p>
<ul>
<li>默认情况下推荐使用引号引用包含变量、命令替换符、空格或shell元字符的字符串</li>
<li>在有明确要求必须使用无引号扩展的情况下，可不用引号</li>
<li>字符串为单词类型时才推荐用引号，而非命令选项或者路径名</li>
<li>不要对整数使用引号</li>
<li>特别注意 <code>[[</code> 中模式匹配的引号规则</li>
<li>在无特殊情况下，推荐使用 <code>$@</code> 而非 <code>$*</code></li>
</ul>
<p>以下通过示例说明：</p>
<pre><code># '单引号' 表示禁用变量替换
# "双引号" 表示需要变量替换

# 示例1： 命令替换需使用双引号
flag="$(some_command and its args "$@" 'quoted separately')"

# 示例2：常规变量需使用双引号
echo "${flag}"

# 示例3：整数不使用引号
value=32
# 示例4：即便命令替换输出为整数，也需要使用引号
number="$(generate_number)"

# 示例5：单词可以使用引号，但不作强制要求
readonly USE_INTEGER='true'

# 示例6：输出特殊符号使用单引号或转义
echo 'Hello stranger, and well met. Earn lots of $$$'
echo "Process $$: Done making \$\$\$."

# 示例7：命令参数及路径不需要引号
grep -li Hugo /dev/null "$1"

# 示例8：常规变量用双引号，ccs可能为空的特殊情况可不用引号
git send-email --to "${reviewers}" ${ccs:+"--cc" "${ccs}"}

# 示例9：正则用单引号，$1可能为空的特殊情况可不用引号
grep -cP '([Ss]pecial|\|?characters*)$' ${1:+"$1"}

# 示例10：位置参数传递推荐带引号的"$@"，所有参数作为单字符串传递用带引号的"$*"
# content of t.sh
func_t() {
    echo num: $#
    echo args: 1:$1 2:$2 3:$3
}

func_t "$@"
func_t "$*"
# 当执行 ./t.sh a b c 时输出如下：
num: 3
args: 1:a 2:b 3:c
num: 1
args: 1:a b c 2: 3:
</code></pre>
<h4 id="命令替换">命令替换</h4>
<p>使用 <code>$(command)</code> 而不是反引号。</p>
<p>因反引号如果要嵌套则要求用反斜杠转义内部的反引号。而 <code>$(command)</code> 形式的嵌套无需转义，且可读性更高。</p>
<p>正例：</p>
<pre><code>var="$(command "$(command1)")"
</code></pre>
<p>反例：</p>
<pre><code>var="`command \`command1\``"
</code></pre>
<h4 id="条件测试">条件测试</h4>
<p>使用 <code>[[ ... ]]</code> ，而不是 <code>[</code> , <code>test</code> , 和 <code>/usr/bin/[</code> 。</p>
<p>因为在 <code>[[</code> 和 <code>]]</code> 之间不会出现路径扩展或单词切分，所以使用 <code>[[ ... ]]</code> 能够减少犯错。且 <code>[[ ... ]]</code> 支持正则表达式匹配，而 <code>[ ... ]</code> 不支持。
参考以下示例：</p>
<pre><code># 示例1：正则匹配，注意右侧没有引号
# 详尽细节参考：http://tiswww.case.edu/php/chet/bash/FAQ 中E14部分
if [[ "filename" =~ ^[[:alnum:]]+name ]]; then
    echo "Match"
fi

# 示例2：严格匹配字符串"f*"(本例为不匹配)
if [[ "filename" == "f*" ]]; then
    echo "Match"
fi

# 示例3：[]中右侧不加引号将出现路径扩展，如果当前目录下有f开头的多个文件将报错[: too many arguments
if [ "filename" == f* ]; then
    echo "Match"
fi
</code></pre>
<h4 id="字符串测试">字符串测试</h4>
<p>尽可能使用变量引用，而非字符串过滤。</p>
<p>Bash可以很好的处理空字符串测试，请使用空/非空字符串测试方法，而不是过滤字符，让代码具有更高的可读性。
正例：</p>
<pre><code>if [[ "${my_var}" = "some_string" ]]; then
    do_something
fi
</code></pre>
<p>反例：</p>
<pre><code>if [[ "${my_var}X" = "some_stringX" ]]; then
    do_something
fi
</code></pre>
<p>正例：</p>
<pre><code># 使用-z测试字符串为空
if [[ -z "${my_var}" ]]; then
    do_something
fi
</code></pre>
<p>反例：</p>
<pre><code># 使用空引号测试空字符串，能用但不推荐
if [[ "${my_var}" = "" ]]; then
    do_something
fi
</code></pre>
<p>正例：</p>
<pre><code># 使用-n测试非空字符串
if [[ -n "${my_var}" ]]; then
    do_something
fi
</code></pre>
<p>反例：</p>
<pre><code># 测试字符串非空，能用但不推荐
if [[ "${my_var}" ]]; then
    do_something
fi
</code></pre>
<h4 id="文件名扩展">文件名扩展</h4>
<p>当进行文件名的通配符扩展时，请指定明确的路径。</p>
<p>当目录中有特殊文件名如以 <code>-</code> 开头的文件时，使用带路径的扩展通配符 <code>./*</code> 比不带路径的 <code>*</code> 要安全很多。</p>
<pre><code># 例如目录下有以下4个文件和子目录：
# -f  -r  somedir  somefile

# 未指定路径的通配符扩展会把-r和-f当作rm的参数，强制删除文件：
psa@bilby$ rm -v *
removed directory: `somedir'
removed `somefile'

# 而指定了路径的则不会:
psa@bilby$ rm -v ./*
removed `./-f'
removed `./-r'
rm: cannot remove `./somedir': Is a directory
removed `./somefile'
</code></pre>
<h4 id="慎用eval">慎用eval</h4>
<p>应该避免使用eval。</p>
<p>Eval在用于分配变量时会修改输入内容，但设置变量的同时并不能检查这些变量是什么。
反例：</p>
<pre><code># 以下设置的内容及成功与否并不明确
eval $(set_my_variables)
</code></pre>
<h4 id="慎用管道连接while循环">慎用管道连接while循环</h4>
<p>请使用进程替换或者for循环，而不是通过管道连接while循环。</p>
<p>这是因为在管道之后的while循环中，命令是在一个子shell中运行的，因此对变量的修改是不能传递给父shell的。</p>
<p>这种管道连接while循环中的隐式子shell使得bug定位非常困难。
反例：</p>
<pre><code>last_line='NULL'
your_command | while read line; do
    last_line="${line}"
done

# 以下会输出'NULL'：
echo "${last_line}"
</code></pre>
<p>如果你确定输入中不包含空格或者其他特殊符号（通常不是来自用户输入），则可以用for循环代替。
例如：</p>
<pre><code>total=0
# 仅当返回结果中无空格等特殊符号时以下可正常执行：
for value in $(command); do
    total+="${value}"
done
</code></pre>
<p>使用进程替换可实现重定向输出，但是请将命令放入显式子shell，而非while循环创建的隐式子shell。
例如：</p>
<pre><code>total=0
last_file=
# 注意两个&lt;之间有空格，第一个为重定向，第二个&lt;()为进程替换
while read count filename; do
    total+="${count}"
    last_file="${filename}"
done &lt; &lt;(your_command | uniq -c)

echo "Total = ${total}"
echo "Last one = ${last_file}"
</code></pre>
<h4 id="检查返回值">检查返回值</h4>
<p>总是检查返回值，且提供有用的返回值。</p>
<p>对于非管道命令，使用 <code>$?</code> 或直接通过 <code>if</code> 语句来检查以保持其简洁。</p>
<p>例如：</p>
<pre><code># 使用if语句判断执行结果
if ! mv "${file_list}" "${dest_dir}/" ; then
    echo "Unable to move ${file_list} to ${dest_dir}" &gt;&amp;2
    exit "${E_BAD_MOVE}"
fi

# 或者使用$?
mv "${file_list}" "${dest_dir}/"
if [[ $? -ne 0 ]]; then
    echo "Unable to move ${file_list} to ${dest_dir}" &gt;&amp;2
    exit "${E_BAD_MOVE}"
fi
</code></pre>
<h4 id="内建命令和外部命令">内建命令和外部命令</h4>
<p>当内建命令可以完成相同的任务时，在shell内建命令和调用外部命令之间，应尽量选择内建命令。</p>
<p>因内建命令相比外部命令而言会产生更少的依赖，且多数情况调用内建命令比调用外部命令可以获得更好的性能（通常外部命令会产生额外的进程开销）。</p>
<p>正例：</p>
<pre><code># 使用内建的算术扩展
addition=$((${X} + ${Y}))
# 使用内建的字符串替换
substitution="${string/#foo/bar}"
</code></pre>
<p>反例：</p>
<pre><code># 调用外部命令进行简单的计算
addition="$(expr ${X} + ${Y})"
# 调用外部命令进行简单的字符串替换
substitution="$(echo "${string}" | sed -e 's/^foo/bar/')"
</code></pre>
<h4 id="文件加载">文件加载</h4>
<p>加载外部库文件不建议用使用<code>.</code>，建议使用<code>source</code>，已提升可阅读性。
正例：</p>
<pre><code>source my_libs.sh
</code></pre>
<p>反例：</p>
<pre><code>. my_libs.sh
</code></pre>
<h4 id="内容过滤与统计">内容过滤与统计</h4>
<p>除非必要情况，尽量使用单个命令及其参数组合来完成一项任务，而非多个命令加上管道的不必要组合。
常见的不建议的用法例如：cat和grep连用过滤字符串; cat和wc连用统计行数; grep和wc连用统计行数等。</p>
<p>正例：</p>
<pre><code>grep net.ipv4 /etc/sysctl.conf
grep -c net.ipv4 /etc/sysctl.conf
wc -l /etc/sysctl.conf
</code></pre>
<p>反例：</p>
<pre><code>cat /etc/sysctl.conf | grep net.ipv4
grep net.ipv4 /etc/sysctl.conf | wc -l
cat /etc/sysctl.conf | wc -l
</code></pre>
<h4 id="正确使用返回与退出">正确使用返回与退出</h4>
<p>除特殊情况外，几乎所有函数都不应该使用<code>exit</code>直接退出脚本，而应该使用<code>return</code>进行返回，以便后续逻辑中可以对错误进行处理。
正例：</p>
<pre><code># 当函数返回后可以继续执行cleanup
my_func() {
    [[ -e /dummy ]] || return 1
}

cleanup() {
    ...
}

my_func
cleanup
</code></pre>
<p>反例：</p>
<pre><code># 当函数退出时，cleanup将不会被执行
my_func() {
    [[ -e /dummy ]] || exit 1
}

cleanup() {
    ...
}

my_func
cleanup
</code></pre>
<h2 id="附常用工具">附：常用工具</h2>
<p>推荐以下工具帮助我们进行代码的规范：</p>
<ul>
<li><a href="https://shellcheck.storage.googleapis.com/index.html" title="shell script analysis tool">ShellCheck</a></li>
</ul>]]></content:encoded>
            <category>bash</category>
        </item>
        <item>
            <title><![CDATA[HIVE中常见的小文件合并方法]]></title>
            <link>https://itxx00.github.io/notes/blog/2019/09/02/hive-small-file</link>
            <guid>https://itxx00.github.io/notes/blog/2019/09/02/hive-small-file</guid>
            <pubDate>Mon, 02 Sep 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[hive使用过程中应尽量避免产生小文件]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>介绍hive小文件常见处理方法</p>
</blockquote>
<h2 id="hive的文件产生过程">hive的文件产生过程</h2>
<h2 id="小文件太多的影响">小文件太多的影响</h2>
<h2 id="为什么会产生小文件">为什么会产生小文件</h2>
<h2 id="如何处理小文件">如何处理小文件</h2>
<h3 id="case-1">case 1</h3>
<pre><code>INSERT OVERWRITE TABLE tb1
    SELECT * FROM tb2
ORDER BY 1;
ALTER TABLE tb2 RENAME TO b_tb2;
ALTER TABLE tb1 RENAME TO tb2;

</code></pre>
<h3 id="case-2">case 2</h3>
<pre><code>INSERT TABLE tb1
SELECT c1, c2 FROM (
    SELECT c1, c2
    FROM tb2
    WHERE xxx
      AND xxx
) t
ORDER BY c1, c2;
</code></pre>
<h3 id="case-3">case 3</h3>
<pre><code>SELECT c1
FROM  (
    xxx
) t
GROUP BY x;
</code></pre>
<h3 id="case-4">case 4</h3>
<pre><code>INSERT OVERWRITE TABLE tb1
SELECT
    xxx
FROM
    xxx
    WHERE
        xxx) t
distribute by rand();
</code></pre>
<h3 id="case-5">case 5</h3>
<pre><code>INSERT TABLE tb1
SELECT c1,c2
FROM tb2
WHERE xxx
sort by c1;
</code></pre>]]></content:encoded>
            <category>hive</category>
        </item>
        <item>
            <title><![CDATA[系统中的随机数和熵值]]></title>
            <link>https://itxx00.github.io/notes/blog/2019/05/12/random-and-entropy-in-centos7</link>
            <guid>https://itxx00.github.io/notes/blog/2019/05/12/random-and-entropy-in-centos7</guid>
            <pubDate>Sun, 12 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[简单总结一下系统中的随机数以及相关问题]]></description>
            <content:encoded><![CDATA[<blockquote>
<p>本文试着总结系统中的随机数前前后后以及管理中需要注意的问题 [先欠着]</p>
</blockquote>
<h2 id="1-什么是随机数">1 什么是随机数？</h2>
<p>随机数就是无法预测的数</p>
<h2 id="2-随机数有什么用">2 随机数有什么用？</h2>
<p>随机是为了安全</p>
<h2 id="3-如何获得随机数">3 如何获得随机数？</h2>
<p>/dev/random
/dev/urandom
/proc/sys/kernel/random/entropy_avail</p>
<h2 id="4-会有哪些问题">4 会有哪些问题？</h2>
<p>1 随机数数产生速度慢
2 影响上层应用</p>
<h2 id="haveged-和-rng-tools">haveged 和 rng-tools</h2>]]></content:encoded>
            <category>centos7</category>
            <category>random</category>
            <category>entropy</category>
        </item>
    </channel>
</rss>